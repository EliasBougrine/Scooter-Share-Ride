{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scooter Ride Share Company"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Introduction\n",
    "\n",
    "A potential company, XXXXXXXX, is going to become the latest Scooter Ride Share service — the “Uber for Scooters”. We have built a basic landing page to collect and measure interest in the product, and have data about potential riders who sign up: whether they signed up or not as well as some of their characteristics such as their country, the marketing channel, their age, whether they are repeat visitors and the number of pages visited during that session (as a proxy for site activity/time spent on site).\n",
    "\n",
    "This project is to understand the potential rider base, and build a model that predicts conversion rate, and based on the model, come up with ideas to best go after the opportunity in the new Scooter Ride Share market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Import the data\n",
    "\n",
    "The rider hit data is available for download in this repsitory at [data/conversion_data.csv](data/conversion_data.csv):\n",
    "\n",
    "The table has information about visitors during one session. Each row is a visitor session.\n",
    "\n",
    "### Columns\n",
    "\n",
    " - **country** : user country based on the IP address\n",
    " - **age** : user age. Self-reported at sign-up step\n",
    " - **new_user** : whether the user created the account during this session or had already an account and simply came back to the site\n",
    " - **source** : marketing channel source\n",
    "   Ads: came to the site by clicking on an advertisement\n",
    "   Seo: came to the site by clicking on search results\n",
    "   Direct: came to the site by directly typing the URL on the browser \n",
    " - **total_pages_visited**: number of total pages visited during the session. This is a proxy for time spent on site and engagement during the session.\n",
    " - **converted**: this is our label. 1 means they converted within the session, 0 means they left without buying anything. The company goal is to increase conversion rate: # conversions / total sessions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (316200, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "      <th>new_user</th>\n",
       "      <th>source</th>\n",
       "      <th>total_pages_visited</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UK</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>Ads</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>Seo</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>Seo</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>China</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>Seo</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>Seo</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  age  new_user source  total_pages_visited  converted\n",
       "0      UK   25         1    Ads                    1          0\n",
       "1      US   23         1    Seo                    5          0\n",
       "2      US   28         1    Seo                    4          0\n",
       "3   China   39         1    Seo                    5          0\n",
       "4      US   30         1    Seo                    6          0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/conversion_data.csv')\n",
    "print('shape: ', data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART I - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['UK', 'US', 'China', 'Germany'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['country'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The users come from 4 different countries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
       "        30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
       "        43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
       "        56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,\n",
       "        69,  70,  72,  73,  77,  79, 111, 123], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(list(data['age'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it shows that some user are 111 or 123 years old. It seems to be an error due to the acquisition of the data. Moreover, it seems interesting to see that we have users older than 60 years old for a Scooter Ride Share Service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users older than 60:  237\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Number of users older than 60: ', data.loc[data['age']>60,'age'].shape[0])\n",
    "sns.countplot(data.loc[data['age']>60,'age']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many of these users decided to use the service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 61, 111, 123], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(data.loc[(data['age']>60) & (data['converted'] == 1),'age'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of converted users older than 60:  3\n",
      "Age of these users:  [ 61 111 123]\n"
     ]
    }
   ],
   "source": [
    "print('Number of converted users older than 60: ', data.loc[(data['age']>60) & (data['converted'] == 1),'age'].shape[0])\n",
    "print('Age of these users: ', np.sort(data.loc[(data['age']>60) & (data['converted'] == 1),'age'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It makes more sense: the users that use the website finally decide not to use the service. However, we will delete in the second part the points corresponding to the users 111 and 123 years old."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) New User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['new_user'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems coherent: If the user is new, the value is 1. Otherwise, the value is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ads', 'Seo', 'Direct'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['source'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentionned in the README file, the 3 possible sources are advertisement, search results, or URL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) total pages visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  5,  4,  6,  2,  8,  7,  3,  9, 14, 10, 11, 18, 15, 19, 12, 13,\n",
       "       21, 17, 23, 16, 25, 26, 20, 22, 24, 27, 28, 29], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['total_pages_visited'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of pages visited by a user during the session varies from 1 to 29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['converted'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is coherent, this column only contains 0 or 1: 0 means the user left the session without buying anything while 1 means the user accepted a trip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this analysis, we have a better understanding of the data. The data don't contain any NaN or unexpected value. Let's now prepare the data in order to build our prediction model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART II - Data Cleaning and One Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For many of the data (Country and Source columns), we want to have integer values instead of string values. In fact, these columns contain categorical data, not numerical, so we cannot use them as-is for regression.\n",
    "\n",
    "A first method would be to affect each of the unique values to an integer through the mean of a dictionnary and replace in the DataFrame the string by these integers.\n",
    "\n",
    "For instance, we could create the following dictionnary for the countries:\n",
    "dico_country = {\n",
    "    'UK': 1,\n",
    "    'US': 2,\n",
    "    'China': 3,\n",
    "    'Germany': 4\n",
    "}\n",
    "\n",
    "However, by using this method, we create a different weight for each value of the unique values.\n",
    "\n",
    "\n",
    "Fortunately, we will perform a one-hot encoding transformation on these categorical variables to convert them into numerical variables. The transformation works as follows: create a new column for every unique value in a categorical variable. The column contains a 1 if the variable originally had the corresponding value, otherwise the column contains a 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But first, we noticed during the Exploratory Data Analysis that some customers are 111 or 123 years old. This seems to be an error. In order to have a better accuracy when building our prediction model, we will not take these rows into consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (316198, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "      <th>new_user</th>\n",
       "      <th>source</th>\n",
       "      <th>total_pages_visited</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UK</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>Ads</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>Seo</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>Seo</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>China</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>Seo</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>Seo</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  age  new_user source  total_pages_visited  converted\n",
       "0      UK   25         1    Ads                    1          0\n",
       "1      US   23         1    Seo                    5          0\n",
       "2      US   28         1    Seo                    4          0\n",
       "3   China   39         1    Seo                    5          0\n",
       "4      US   30         1    Seo                    6          0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.loc[ (data['age'] != 111) & (data['age'] != 123) , : ]\n",
    "print('shape: ', data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only have 2 row less than the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['country', 'age', 'new_user', 'source', 'total_pages_visited',\n",
       "       'converted'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_columns = data.columns\n",
    "all_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform one-hot encoding we can use scikit-learn's DictVectorizer class. To use the class, we have to convert our dataframe into a list of dictionaries. The DictVectorizer class automatically one-hot encodes the categorical data (which needs to be strings) and leaves numerical data untouched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [23.,  0.,  0., ...,  0.,  1.,  5.],\n",
       "       [28.,  0.,  0., ...,  0.,  1.,  4.],\n",
       "       ...,\n",
       "       [25.,  0.,  1., ...,  0.,  0.,  4.],\n",
       "       [22.,  0.,  0., ...,  0.,  1.,  4.],\n",
       "       [24.,  0.,  0., ...,  0.,  0.,  4.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = data[all_columns].to_dict(orient = 'records')\n",
    "encoder = DictVectorizer(sparse = False)\n",
    "encoded_X = encoder.fit_transform(records)\n",
    "encoded_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better sense of the transformed data, we can display it with the column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the encoded dataset:  (316198, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>converted</th>\n",
       "      <th>country=China</th>\n",
       "      <th>country=Germany</th>\n",
       "      <th>country=UK</th>\n",
       "      <th>country=US</th>\n",
       "      <th>new_user</th>\n",
       "      <th>source=Ads</th>\n",
       "      <th>source=Direct</th>\n",
       "      <th>source=Seo</th>\n",
       "      <th>total_pages_visited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  converted  country=China  country=Germany  country=UK  country=US  \\\n",
       "0  25.0        0.0            0.0              0.0         1.0         0.0   \n",
       "1  23.0        0.0            0.0              0.0         0.0         1.0   \n",
       "2  28.0        0.0            0.0              0.0         0.0         1.0   \n",
       "3  39.0        0.0            1.0              0.0         0.0         0.0   \n",
       "4  30.0        0.0            0.0              0.0         0.0         1.0   \n",
       "\n",
       "   new_user  source=Ads  source=Direct  source=Seo  total_pages_visited  \n",
       "0       1.0         1.0            0.0         0.0                  1.0  \n",
       "1       1.0         0.0            0.0         1.0                  5.0  \n",
       "2       1.0         0.0            0.0         1.0                  4.0  \n",
       "3       1.0         0.0            0.0         1.0                  5.0  \n",
       "4       1.0         0.0            0.0         1.0                  6.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(data = encoded_X, columns = encoder.feature_names_)\n",
    "print('Shape of the encoded dataset: ', data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have 11 features, and this will make our prediction model more accurrate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need to change anything for the 'new_user', the 'total_pages_visited', and the 'converted' columns since these three features only have integers. Let's now build the prediction model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART III - Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Training Validation Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we have is all the data we have available for both training the model and validating the model that we train. We therefore need to split the data into separate training and validation datasets. We will need this validation data to assess the performance of our classifier once we are finished training. Note that we set the seed (random_state) to 42. This will produce a pseudo-random sequence of random numbers that is the same for every runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (284578, 11)\n",
      "val shape:  (31620, 11)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(data, test_size = 0.1, random_state = 42)\n",
    "print('train shape: ', train.shape)\n",
    "print('val shape: ', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Retrieve X_train and Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We divide our training dataset into a features matrix and a real values (converted or not converted) vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'country=China', 'country=Germany', 'country=UK', 'country=US',\n",
       "       'new_user', 'source=Ads', 'source=Direct', 'source=Seo',\n",
       "       'total_pages_visited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = data.columns.drop(['converted'])\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Features matrix\n",
    "X_train = train[features]\n",
    "\n",
    "# We normalize the matrix\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "# Real Values vector\n",
    "Y_train = train['converted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing the features helps us to have a better accuracy when building our model. Each feature will contain values between 0 and 1. This will also permit us to interpret the importance of each feature after building the prediction model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Baseline Model\n",
    "\n",
    "We check the class distribution to build the baseline model. This model will predict only 0 or only 1 (depending on the maximum number of values of these two classes).\n",
    "\n",
    "The accuracy of this very basic model is the one that we will try to beat by building more complex algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(['0', '1'], Y_train.value_counts())\n",
    "plt.title('Number of 0 and 1 in the Training Dataset');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the baseline model will predict only 0. Therefore, the accuracy will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the baseline model on the training dataset is:  0.9676749432493025\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy of the baseline model on the training dataset is: ', Y_train.value_counts()[0]/len(Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) X_test and Y_test\n",
    "\n",
    "The test dataset is used to assess the performance of our classifier once we are finished training. We divide our test dataset into a features matrix and a vector of the values that we want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features matrix\n",
    "X_test = test[features]\n",
    "\n",
    "# We normalize the matrix\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Real Values vector\n",
    "Y_test = test['converted'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the baseline model will predict only 0. Therefore, the accuracy will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the baseline model on the test dataset is:  0.9684060721062618\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy of the baseline model on the test dataset is: ', Y_test.value_counts()[0]/len(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PART VI - Evaluating Classifiers\n",
    "\n",
    "First, we are evaluating accuracy on the training set, which may lead to a misleading accuracy measure, especially if we used the training set to identify discriminative features. \n",
    "\n",
    "Presumably, our classifier will be used for filtering. There are two kinds of errors we can make:\n",
    "- False positive (FP): A user that will not buy the service and that will be considered as converted.\n",
    "- False negative (FN): A user that will be buy the service and that won't be considered as converted.\n",
    "\n",
    "These definitions depend both on the true labels and the predicted labels. False positives and false negatives may be of differing importance, leading us to consider more ways of evaluating a classifier, in addition to overall accuracy:\n",
    "\n",
    "**Precision** measures the proportion $\\frac{\\text{TP}}{\\text{TP} + \\text{FP}}$ of predicted conversions that are actually conversions.\n",
    "\n",
    "**Recall** measures the proportion $\\frac{\\text{TP}}{\\text{TP} + \\text{FN}}$ of conversions that were correctly flagged as conversions. \n",
    "\n",
    "**False-alarm rate** measures the proportion $\\frac{\\text{FP}}{\\text{FP} + \\text{TN}}$ of non-conversions that were incorrectly flagged as conversions. \n",
    "\n",
    "The following image summarizes these errors:\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/700px-Precisionrecall.svg.png\" width=\"500px\">\n",
    "\n",
    "Note that a true positive (TP) is a user that will buy the service and will be considered as converted, and a true negative (TN) is a user that won't buy anything and that won't be considered as converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add the results in the Test and Training data Frame\n",
    "Test = pd.DataFrame(columns = ['Model', 'Accuracy', 'Test_Precision', 'Test_Recall', 'Test_FAR'])\n",
    "Training = pd.DataFrame(columns = ['Model', 'Accuracy', 'Training_Precision', 'Training_Recall', 'Training_FAR'])\n",
    "\n",
    "def evaluate_classifier(model, train_or_test, name):\n",
    "     \n",
    "    global Test\n",
    "    global Training\n",
    "    \n",
    "    if train_or_test == 'train':\n",
    "        \n",
    "        predictions = model.predict(X_train)\n",
    "        \n",
    "        TP = sum((predictions == Y_train) & (predictions == 1))\n",
    "        TN = sum((predictions == Y_train) & (predictions == 0))\n",
    "        FP = sum((predictions != Y_train) & (predictions == 1))\n",
    "        FN = sum((predictions != Y_train) & (predictions == 0))\n",
    "    \n",
    "        precision = TP / (TP + FP) \n",
    "        recall = TP / (TP + FN) \n",
    "        false_alarm_rate = FP / (FP + TN)\n",
    "        accuracy = (TP + TN)/len(Y_train)\n",
    "        \n",
    "        Training = Training.append({'Model': name,\n",
    "                                    'Accuracy' : accuracy,\n",
    "                                    'Training_Precision' : precision, \n",
    "                                    'Training_Recall' : recall, \n",
    "                                    'Training_FAR' : false_alarm_rate}\n",
    "                           , ignore_index=True)\n",
    "        \n",
    "        print('Accuracy score on the training dataset:', accuracy)\n",
    "        print('\\nThe training precision is: ', precision)\n",
    "        print('\\nThe training recall is: ', recall)\n",
    "        print('\\nThe training False Alarm Rate is: ', false_alarm_rate)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        TP = sum((predictions == Y_test) & (predictions == 1))\n",
    "        TN = sum((predictions == Y_test) & (predictions == 0))\n",
    "        FP = sum((predictions != Y_test) & (predictions == 1))\n",
    "        FN = sum((predictions != Y_test) & (predictions == 0))\n",
    "        \n",
    "        precision = TP / (TP + FP) \n",
    "        recall = TP / (TP + FN) \n",
    "        false_alarm_rate = FP / (FP + TN)\n",
    "        accuracy = (TP + TN)/len(Y_test)\n",
    "        \n",
    "        Test = Test.append({'Model': name,\n",
    "                            'Accuracy' : accuracy,\n",
    "                            'Test_Precision' : precision, \n",
    "                            'Test_Recall' : recall, \n",
    "                            'Test_FAR' : false_alarm_rate}\n",
    "                           , ignore_index=True)\n",
    "        \n",
    "        print('Accuracy score on the test dataset:', accuracy)\n",
    "        print('\\nThe test precision is: ', precision)\n",
    "        print('\\nThe test recall is: ', recall)\n",
    "        print('\\nThe test False Alarm Rate is: ', false_alarm_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART VII - Different Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## First Model: Decision Tree\n",
    "\n",
    "While the Decision Tree model is usually not the best model to have a good precision, it is in general good to run it to have a first insight of the data before building a more complex model.\n",
    "\n",
    "This model is often subject to a high variance due to overfitting: if we change the training set, the tree built will be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier()\n",
    "dtree = dtree.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on the training dataset: 0.9880208589560683\n",
      "\n",
      "The training precision is:  0.9064869418702611\n",
      "\n",
      "The training recall is:  0.7018154147189912\n",
      "\n",
      "The training False Alarm Rate is:  0.0024184850696676217\n",
      "\n",
      "\n",
      "Accuracy score on the test dataset: 0.9856103731815307\n",
      "\n",
      "The test precision is:  0.8487179487179487\n",
      "\n",
      "The test recall is:  0.6626626626626627\n",
      "\n",
      "The test False Alarm Rate is:  0.0038535645472061657\n"
     ]
    }
   ],
   "source": [
    "evaluate_classifier(dtree, 'train', name = 'Decision Tree')\n",
    "print('\\n')\n",
    "evaluate_classifier(dtree, 'test', name = 'Decision Tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Random Forest Algorithm\n",
    "\n",
    "This model is in general one the most accurate one that we can build. As a matter of fact, Random Forest Algorithm has multiple random decision trees. Therefore, the noisy information will be cancelled out by the sampling. Although some trees in the forest can overfit, the model has a lower variance while maintaining the same low bias than a decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=150, random_state=0)\n",
    "random_forest.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on the training dataset: 0.9880208589560683\n",
      "\n",
      "The training precision is:  0.8879656928437416\n",
      "\n",
      "The training recall is:  0.7202956843135123\n",
      "\n",
      "The training False Alarm Rate is:  0.003035816093456654\n",
      "\n",
      "\n",
      "Accuracy score on the test dataset: 0.9857685009487666\n",
      "\n",
      "The test precision is:  0.8393077873918418\n",
      "\n",
      "The test recall is:  0.6796796796796797\n",
      "\n",
      "The test False Alarm Rate is:  0.00424545246726103\n"
     ]
    }
   ],
   "source": [
    "evaluate_classifier(random_forest, 'train', name = 'Random Forest Algorithm')\n",
    "print('\\n')\n",
    "evaluate_classifier(random_forest, 'test', name = 'Random Forest Algorithm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Gradient Boosting\n",
    "\n",
    "This model is often used for anomalies detection (very imbalanced dataset): cancer, fraud...\n",
    "\n",
    "It has a lot of flexibility that often provide a predictive accuracy that cannot be beat. However, if the data is noisy, the model is very sensitive to overfitting and will have a high variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_boosting = GradientBoostingClassifier()\n",
    "gradient_boosting.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on the training dataset: 0.9860916866377584\n",
      "\n",
      "The training precision is:  0.8535960059371205\n",
      "\n",
      "The training recall is:  0.6876834438525927\n",
      "\n",
      "The training False Alarm Rate is:  0.003940024475359414\n",
      "\n",
      "\n",
      "Accuracy score on the test dataset: 0.9869070208728653\n",
      "\n",
      "The test precision is:  0.8633540372670807\n",
      "\n",
      "The test recall is:  0.6956956956956957\n",
      "\n",
      "The test False Alarm Rate is:  0.003592305933836256\n"
     ]
    }
   ],
   "source": [
    "evaluate_classifier(gradient_boosting, 'train', name = 'Gradient Boosting')\n",
    "print('\\n')\n",
    "evaluate_classifier(gradient_boosting, 'test', name = 'Gradient Boosting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Logistic Regression\n",
    "\n",
    "The Logistic Regression model can give the user probabilities. This is a huge advantage. However, this model is very sensitive to correlated features: the variance of the model can be very high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elias\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on the training dataset: 0.9860881726626795\n",
      "\n",
      "The training precision is:  0.8543413578577225\n",
      "\n",
      "The training recall is:  0.6867050766387651\n",
      "\n",
      "The training False Alarm Rate is:  0.0039109736036516945\n",
      "\n",
      "\n",
      "Accuracy score on the test dataset: 0.987033523086654\n",
      "\n",
      "The test precision is:  0.867665418227216\n",
      "\n",
      "The test recall is:  0.6956956956956957\n",
      "\n",
      "The test False Alarm Rate is:  0.0034616766271513013\n"
     ]
    }
   ],
   "source": [
    "evaluate_classifier(logistic_regression, 'train', name = 'Logistic Regression')\n",
    "print('\\n')\n",
    "evaluate_classifier(logistic_regression, 'test', name = 'Logistic Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Support Vector Machine\n",
    "\n",
    "This model usually works very well when we have a lot of features. However, it is difficult to interpret the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = svm.SVC()\n",
    "svm.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on the training dataset: 0.9858000267062106\n",
      "\n",
      "The training precision is:  0.8899304505594194\n",
      "\n",
      "The training recall is:  0.6398521578432438\n",
      "\n",
      "The training False Alarm Rate is:  0.002643629325402445\n",
      "\n",
      "\n",
      "Accuracy score on the test dataset: 0.9862428842504743\n",
      "\n",
      "The test precision is:  0.8852459016393442\n",
      "\n",
      "The test recall is:  0.6486486486486487\n",
      "\n",
      "The test False Alarm Rate is:  0.00274321544038405\n"
     ]
    }
   ],
   "source": [
    "evaluate_classifier(svm, 'train', name = 'Support Vector Machine')\n",
    "print('\\n')\n",
    "evaluate_classifier(svm, 'test', name = 'Support Vector Machine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Adaboost Classifier\n",
    "\n",
    "This model is similar to the Gradient Boosting Model but add weight on the different decision trees. It is in general as performing as SVM and can achieve similar results with much less tweaking parameters or settings. However, it is really sensitive to noisy data and outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost = AdaBoostClassifier()\n",
    "adaboost.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on the training dataset: 0.9857367751547906\n",
      "\n",
      "The training precision is:  0.8549723756906077\n",
      "\n",
      "The training recall is:  0.6728992281769758\n",
      "\n",
      "The training False Alarm Rate is:  0.0038129269116381425\n",
      "\n",
      "\n",
      "Accuracy score on the test dataset: 0.9865275142314991\n",
      "\n",
      "The test precision is:  0.8631178707224335\n",
      "\n",
      "The test recall is:  0.6816816816816816\n",
      "\n",
      "The test False Alarm Rate is:  0.003526991280493779\n"
     ]
    }
   ],
   "source": [
    "evaluate_classifier(adaboost, 'train', name = 'Adaboost Classifier')\n",
    "print('\\n')\n",
    "evaluate_classifier(adaboost, 'test', name = 'Adaboost Classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART VIII - Conclusions\n",
    "\n",
    "Here are the results that we get for the training and test datasets. We will choose our model according to the best metric on the test datasets.\n",
    "\n",
    "Some notes:\n",
    "- Decision Tree: While it has one of the best precision on the training dataset, the Decision Tree model has one of the lowest precision on the test dataset. It seems understandable since this model is the one with the highest variance.\n",
    "\n",
    "- For all of the four last models, we can notice that their accuracy is almost the same (~ 0.98). We also can see that they have a very low variance since the precision on the training and validation datasets are really close.\n",
    "\n",
    "**According to first the precision, and then to the accuracy, the best model is the Support Vector Machine. It has an accuracy of 98.62%, and the best precision (88.52%) on the test dataset.**\n",
    "\n",
    "Finally, we also can notice that this model has a higher accuracy than the baseline model (96.77%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Training_Precision</th>\n",
       "      <th>Training_Recall</th>\n",
       "      <th>Training_FAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.988021</td>\n",
       "      <td>0.906487</td>\n",
       "      <td>0.701815</td>\n",
       "      <td>0.002418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Algorithm</td>\n",
       "      <td>0.988021</td>\n",
       "      <td>0.887966</td>\n",
       "      <td>0.720296</td>\n",
       "      <td>0.003036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.986092</td>\n",
       "      <td>0.853596</td>\n",
       "      <td>0.687683</td>\n",
       "      <td>0.003940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.986088</td>\n",
       "      <td>0.854341</td>\n",
       "      <td>0.686705</td>\n",
       "      <td>0.003911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.985800</td>\n",
       "      <td>0.889930</td>\n",
       "      <td>0.639852</td>\n",
       "      <td>0.002644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adaboost Classifier</td>\n",
       "      <td>0.985737</td>\n",
       "      <td>0.854972</td>\n",
       "      <td>0.672899</td>\n",
       "      <td>0.003813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model  Accuracy  Training_Precision  Training_Recall  \\\n",
       "0            Decision Tree  0.988021            0.906487         0.701815   \n",
       "1  Random Forest Algorithm  0.988021            0.887966         0.720296   \n",
       "2        Gradient Boosting  0.986092            0.853596         0.687683   \n",
       "3      Logistic Regression  0.986088            0.854341         0.686705   \n",
       "4   Support Vector Machine  0.985800            0.889930         0.639852   \n",
       "5      Adaboost Classifier  0.985737            0.854972         0.672899   \n",
       "\n",
       "   Training_FAR  \n",
       "0      0.002418  \n",
       "1      0.003036  \n",
       "2      0.003940  \n",
       "3      0.003911  \n",
       "4      0.002644  \n",
       "5      0.003813  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Test_Precision</th>\n",
       "      <th>Test_Recall</th>\n",
       "      <th>Test_FAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.985610</td>\n",
       "      <td>0.848718</td>\n",
       "      <td>0.662663</td>\n",
       "      <td>0.003854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Algorithm</td>\n",
       "      <td>0.985769</td>\n",
       "      <td>0.839308</td>\n",
       "      <td>0.679680</td>\n",
       "      <td>0.004245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.986907</td>\n",
       "      <td>0.863354</td>\n",
       "      <td>0.695696</td>\n",
       "      <td>0.003592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.987034</td>\n",
       "      <td>0.867665</td>\n",
       "      <td>0.695696</td>\n",
       "      <td>0.003462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.986243</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.002743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adaboost Classifier</td>\n",
       "      <td>0.986528</td>\n",
       "      <td>0.863118</td>\n",
       "      <td>0.681682</td>\n",
       "      <td>0.003527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model  Accuracy  Test_Precision  Test_Recall  Test_FAR\n",
       "0            Decision Tree  0.985610        0.848718     0.662663  0.003854\n",
       "1  Random Forest Algorithm  0.985769        0.839308     0.679680  0.004245\n",
       "2        Gradient Boosting  0.986907        0.863354     0.695696  0.003592\n",
       "3      Logistic Regression  0.987034        0.867665     0.695696  0.003462\n",
       "4   Support Vector Machine  0.986243        0.885246     0.648649  0.002743\n",
       "5      Adaboost Classifier  0.986528        0.863118     0.681682  0.003527"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommandations and Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to improve the model, it could be useful to have more features such as:\n",
    "   - The gender of the user\n",
    "   - The price of the service\n",
    "   - The total duration of the ride\n",
    "   \n",
    "These features could improve the precision of the classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
